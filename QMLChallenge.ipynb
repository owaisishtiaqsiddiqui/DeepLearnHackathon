{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGTW8Y_lU4wa",
        "outputId": "61e5e85a-2384-4727-c08d-3870fc458a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.42.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.42 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.42.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.42->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.7.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.42.1-py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.2-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.42.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.2 diastatic-malt-2.15.2 pennylane-0.42.1 pennylane-lightning-0.42.0 rustworkx-0.16.0 scipy-openblas32-0.3.30.0.2\n"
          ]
        }
      ],
      "source": [
        "%pip install pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Loading in PennyLane"
      ],
      "metadata": {
        "id": "4ArxzdsMXTt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load the dataset\n",
        "data = pd.read_csv('/content/QMLChallenge/data/challenge_higgs_data.csv')\n",
        "\n",
        "X = data.iloc[:, 1:].values  # 28 features per sample\n",
        "y = data.iloc[:, 0].values   # 1 (signal), 0 (background)\n",
        "\n",
        "# 2. Feature Scaling (z-score, then map to [0, π] for angle encoding)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_angle = (X_scaled - X_scaled.min()) / (X_scaled.max() - X_scaled.min()) * np.pi\n"
      ],
      "metadata": {
        "id": "yXeggwaSWu2m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Train/Validation Split"
      ],
      "metadata": {
        "id": "p7QgKGowYQ3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_angle, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "0EtBF76XYNuz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum circuits typically require input data normalized to a specific range (e.g., [0, π] or [−π, π]), so you might map or scale your features accordingly before encoding"
      ],
      "metadata": {
        "id": "Iarbrxy0XXcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Circuit Restrictions"
      ],
      "metadata": {
        "id": "seuJIdi4Xemx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Max qubits per circuit: 20\n",
        "\n",
        "* Main focus: The architecture must feature a quantum neural network (QNN). Hybrid models (classical + quantum) are allowed only if the quantum part is central.\n",
        "\n",
        "* Framework: Use PennyLane; any library available in Google Colab is allowed.\n",
        "\n",
        "* Don’t modify the final cell that plots the ROC curve.\n",
        "\n",
        "* Input dataset: Use only the provided subset for training; the test set is reserved for final evaluation."
      ],
      "metadata": {
        "id": "-OU6PwgIXhNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Quantum Neural Network (QNN) Design"
      ],
      "metadata": {
        "id": "xaZ2FwgPXusK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Building Blocks\n",
        "We’ll need:\n",
        "\n",
        "* Quantum circuit device: On simulator or hardware plugin (here, use the default qubit simulator).\n",
        "\n",
        "* Feature encoding: Embed (part of) your data into the circuit (e.g., via angle encoding or amplitude encoding).\n",
        "\n",
        "* Variational layers: Parameterized gates whose weights are learned during training.\n",
        "\n",
        "* Measurement: Output for each sample is usually the expectation value of a Pauli operator."
      ],
      "metadata": {
        "id": "9GRUnyuvX2fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Pennylane Utility"
      ],
      "metadata": {
        "id": "gFDEPCzeYB76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "n_qubits = 6  # Or 8 for a larger model, but <=20 as per challenge rules\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "def angle_encoding(features):\n",
        "    # Truncate or select first n_qubits features\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "\n",
        "def variational_block(weights):\n",
        "    # One trainable rotation and controlled entangling layer per qubit\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(weights[i], wires=i)\n",
        "    # Entangle neighboring qubits\n",
        "    for i in range(n_qubits-1):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "    qml.CNOT(wires=[n_qubits-1, 0])\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnn_circuit(features, weights):\n",
        "    angle_encoding(features)\n",
        "    variational_block(weights[0])\n",
        "    variational_block(weights[1])\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "metadata": {
        "id": "xhRwQUatW8t3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Classifier Wrapper and Training"
      ],
      "metadata": {
        "id": "Ek_aerHhYpzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(params, x):\n",
        "    weights = params[:-1]\n",
        "    bias = params[-1]\n",
        "    return qnn_circuit(x, weights) + bias\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def binary_cross_entropy(preds, targets):\n",
        "    preds = np.clip(sigmoid(preds), 1e-8, 1-1e-8)\n",
        "    return -np.mean(targets * np.log(preds) + (1 - targets) * np.log(1 - preds))\n",
        "\n",
        "def accuracy(preds, targets):\n",
        "    pred_labels = (sigmoid(preds) > 0.5).astype(int)\n",
        "    return np.mean(pred_labels == targets)"
      ],
      "metadata": {
        "id": "s7Pk4h5tYwbY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "clI57VFoY1B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Prepare parameters\n",
        "init_weights = np.random.randn(n_qubits)\n",
        "init_bias = 0.0\n",
        "params = np.append(init_weights, init_bias)\n",
        "\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    batch_index = np.random.randint(0, len(X_train), batch_size)\n",
        "    X_batch = X_train[batch_index]\n",
        "    y_batch = y_train[batch_index]\n",
        "\n",
        "    def cost(params):\n",
        "        preds = np.array([classifier(params, x) for x in X_batch])\n",
        "        return binary_cross_entropy(preds, y_batch)\n",
        "\n",
        "    params = opt.step(cost, params)\n",
        "\n",
        "    # Evaluate\n",
        "    train_loss = cost(params)\n",
        "    val_preds = np.array([classifier(params, x) for x in X_val[:100]])\n",
        "    val_loss = binary_cross_entropy(val_preds, y_val[:100])\n",
        "    val_acc = accuracy(val_preds, y_val[:100])\n",
        "    print(f\"Epoch {epoch+1:2d}  Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}  Val Acc: {val_acc:.3f}\")\n",
        "\n",
        "# Save weights as required\n",
        "np.save('trained_weights.npy', params[:-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZLSZWhUYzTc",
        "outputId": "cda2d75d-3f58-435f-f956-3d6a6aace270"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1  Loss: 0.7116  Val Loss: 0.7017  Val Acc: 0.460\n",
            "Epoch  2  Loss: 0.7262  Val Loss: 0.7005  Val Acc: 0.460\n",
            "Epoch  3  Loss: 0.6987  Val Loss: 0.6996  Val Acc: 0.480\n",
            "Epoch  4  Loss: 0.7001  Val Loss: 0.6988  Val Acc: 0.470\n",
            "Epoch  5  Loss: 0.6877  Val Loss: 0.6980  Val Acc: 0.460\n",
            "Epoch  6  Loss: 0.6961  Val Loss: 0.6973  Val Acc: 0.470\n",
            "Epoch  7  Loss: 0.6899  Val Loss: 0.6968  Val Acc: 0.500\n",
            "Epoch  8  Loss: 0.6830  Val Loss: 0.6964  Val Acc: 0.480\n",
            "Epoch  9  Loss: 0.6866  Val Loss: 0.6961  Val Acc: 0.460\n",
            "Epoch 10  Loss: 0.6911  Val Loss: 0.6959  Val Acc: 0.460\n",
            "Epoch 11  Loss: 0.6880  Val Loss: 0.6958  Val Acc: 0.440\n",
            "Epoch 12  Loss: 0.6880  Val Loss: 0.6957  Val Acc: 0.440\n",
            "Epoch 13  Loss: 0.6943  Val Loss: 0.6954  Val Acc: 0.450\n",
            "Epoch 14  Loss: 0.6871  Val Loss: 0.6954  Val Acc: 0.450\n",
            "Epoch 15  Loss: 0.6879  Val Loss: 0.6955  Val Acc: 0.460\n",
            "Epoch 16  Loss: 0.6921  Val Loss: 0.6956  Val Acc: 0.460\n",
            "Epoch 17  Loss: 0.6861  Val Loss: 0.6956  Val Acc: 0.450\n",
            "Epoch 18  Loss: 0.6951  Val Loss: 0.6957  Val Acc: 0.440\n",
            "Epoch 19  Loss: 0.7023  Val Loss: 0.6958  Val Acc: 0.440\n",
            "Epoch 20  Loss: 0.6958  Val Loss: 0.6958  Val Acc: 0.440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_classifier(x, weights, bias):\n",
        "    return qnn_circuit(x, weights) + bias\n",
        "\n",
        "# Loss: Mean squared error or cross-entropy (if appropriate)\n",
        "def square_loss(predictions, labels):\n",
        "    return np.mean((predictions - labels)**2)"
      ],
      "metadata": {
        "id": "kYTcAV_RXA3c"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}